\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb,amsfonts}
\usepackage[catalan]{babel} % Language 
% \usepackage{fontspec} <-- AQUESTA LINEA EM PETA (RAUL)
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage[makeroom]{cancel}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0.2cm}

\title{\textsc{APA Problemes} \\ Problema 3 Màxima versemblança}
\author{Lluc Bové \and Raúl Ibàñez \and Joan Marcè \and Aleix Trassera}
\date{}

\begin{document}

\maketitle

\textbf{Considerem un experiment aleatori en què mesurem una determinada variable aleatòria $X$, que segueix una distribució gaussiana, cosa que escrivim $X \sim N(\mu, \sigma^2)$. Prenem $N$ mesures independents de $X$ i obtenim una mostra aleatòria simple $\{x_1, ..., x_N\}$ on cada $x_n$ és una realització de $X$, per $n=1,...,N$. Es demana:}

\begin{enumerate}
\item \textbf{Escriviu la funció de densitat de probabilitat per un $x_n$ qualsevol i construïu la funció log-versemblança (negativa) de la mostra.}

$$p(x_n, \sigma^2, \mu) = \frac{1}{\sqrt{2\pi\sigma}} exp\left(-\frac{(x_n - \mu)^2}{2\sigma^2}\right)$$

$$ -l(\theta) = -l(\mu,\sigma^2) = -\sum_{n=1}^2N ln(p(x_n, \mu, \sigma^2)) = - \sum_{n=1}^N ln \left\{\frac{1}{\sqrt{2\pi\sigma}} exp\left(-\frac{(x_n - \mu)^2}{2\sigma^2}\right) \right\}$$

\item \textbf{Trobeu els estimadors de màxima versemblança $\hat{\mu}$ i $\hat{\sigma}^2$ per $\mu$ i per $\sigma^2$, a partir de la mostra.}

$$\text{Màximitzar} l(\theta) \leftrightarrow \text{Minimitzar} -l(\theta)$$

$$ \frac{\partial(-l)}{\partial\mu} = -\sum_{n=1}^N \frac{2(x_n - \mu)}{2\sigma^2} = 0 \implies 
\sum_{n=1}^N x_n - \mu = 0 \implies \sum_{n=1}^N x_n = N·\mu \implies \boxed{\hat{\mu} = \sum_{n=1}^N \frac{x_n}{N}}$$ 

$$
\frac{\partial(-l)}{\partial\sigma^2} = \frac{N}{2\sigma^2} - \frac{1}{2\sigma^4}\sum_{n=1}^N (x_n - \mu)^2 = 0 \longrightarrow
\begin{aligned}
\footnotesize
\text{Substituïm } \mu \text{ per}\\
\footnotesize
\hat{\mu} \text{ i aïllem } \sigma^2 
\end{aligned} 
\implies \boxed{\hat{\sigma}^2 = \frac{1}{N} \sum_{n=1}^N (x_n - \hat{\mu})^2} $$

\item \textbf{Demostreu que realment són màxims (i no extrems qualssevol).}

$$ \sigma^2 > 0 \implies \frac{\partial^2(-l)}{\partial^2\mu} > 0 \implies \hat{\mu} \text{ és mínim}$$

$$ \hat{\sigma}^2 = \frac{1}{N} \sum_{n=1}^N (x_n - \hat{\mu})^2 \rightarrow \hat{\sigma}^2 \text{ és dependent de } \hat{\mu}$$

\item \textbf{Calculeu els biaixos dels dos estimadors. Determineu si l'estimador per $\mu$ és consistent.}

$$ bias(\hat{\theta}) := \mathbb{E}(\hat{\theta}) - \theta \implies bias(\hat{\mu}) = \underbrace{\mathbb{E}(\hat{\mu})}_{\mu} - \mu = \mu - \mu = 0 $$

$$ \mathbb{E}(\hat{\mu}) = \mathbb{E}\underbrace{\left(\sum_{n=1}^N \frac{x_n}{N}\right)}_{\text{trobat abans}} = \frac{1}{N}\sum_{n=1}^N \mathbb{E}(x_n) = \frac{1}{N}\sum_{n=1}^N \mu = \frac{\cancel{N}}{\cancel{N}}\mu = \mu$$

% Falta afegir el càlcul del vias de sigma^2

\item \textbf{Calculeu la variança de l'estimador per $\mu$, de 3 maneres (que han de coincidir). Pista: useu que si $X_n, X_m \sim N(\mu, \sigma^2)$, llavors:}

$$ \mathbb{E}[X_n · X_m] = 
\begin{cases}
\mu^2 & \text{ si } n \ne m \\
\mu^2 + \sigma^2 & \text{ si } n = m
\end{cases}$$

\begin{enumerate}
    \item Inserint directament el valor de l'estimador i utilitzant les propietats de la variància.
    
    $$ Var(\hat{\mu}) = Var(\frac{1}{N} \sum_{n=1}^{N}(x_n)) = \frac{1}{N^2} \sum_{n=1}^{N}Var(xn) = \frac{1}{N\cancel{^2}}\cancel{N}\sigma^2 = \boxed{\frac{\sigma^2}{N}}    $$
    
    \item Usant la coneguda fòrmula $Var[\hat{\theta}] = \mathbb{E}[\hat{\theta}^2] - (\mathbb{E}[\hat{\theta}])^2$.
    
    $$ \mathbb{E}[\hat{\mu^2}]  = \mathbb{E}[(\frac{1}{N^2}\sum_{n=1}^{N}x_n)^2] = \mathbb{E}[\frac{1}{N^2}(\sum_{n=1}^{N}x_n)(\sum_{m=1}^{M}x_m)] = \frac{1}{N^2}\sum_{n=1}^{N}\sum_{m=1}^{M}\mathbb{E}[x_n x_m] = $$
    $$ = \frac{1}{N^2}(N(\mu^2+\sigma^2)+(N^2-N(\mu^2))) = \frac{\cancel{\mu^2}+\sigma^2}{N}+\mu^2-\cancel{\frac{\mu^2}{N}} = \frac{\sigma^2}{N}+\mu^2 $$
    
    $$ (\mathbb{E}[\mu])^2 = (\mathbb{E}[\frac{1}{N}\sum_{n=1}^{N}xn])^2 = (\frac{1}{N}\sum_{n=1}^{N}\mu)^2 = (\cancel{\frac{1}{N}} \cancel{N} \mu)^2 = \mu^2 $$
    
    $$ \implies  \mathbb{E}[\hat{\theta}^2] - (\mathbb{E}[\hat{\theta}])^2  = \frac{\sigma^2}{N}+\cancel{\mu^2} - \cancel{\mu^2} = \boxed{\frac{\sigma^2}{N}} $$
    
    \item Utilitzant la definició de la variància $Var[\hat{\theta}] = \mathbb{E}[(\mathbb{E}[\hat{\theta}] - \hat{\theta})^2]$.
    
    $$ \mathbb{E}[(\mathbb{E}[\hat{\mu}]-\hat{\mu})^2] = \mathbb{E}[(\mu-\frac{1}{N}\sum_{n=1}^{N}x_n)^2] = \mathbb{E}(\mu-\frac{1}{N}\sum_{n=1}^{N}x_n)(\mu-\frac{1}{N}\sum_{n=1}^{N}x_n) = $$
    
    
\end{enumerate}

\end{enumerate}

\end{document}